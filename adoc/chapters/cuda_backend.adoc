// %%%%%%%%%%%%%%%%%%%%%%%%%%%% begin cuda_backend %%%%%%%%%%%%%%%%%%%%%%%%%%%%

[appendix]
[[chapter:cuda-backend]]
= CUDA backend specification

This chapter describes how the SYCL general programming model is mapped on top
of CUDA, and how the SYCL generic interoperability interface must be
implemented by vendors providing SYCL for CUDA implementations to ensure SYCL
applications written for the CUDA backend are interoperable.

The CUDA backend is enabled using the `sycl::backend::cuda` value of `enum
class backend`. That means that when the CUDA backend is active, the value of
`sycl::is_backend_active<sycl::backend::cuda>::value` will be `true`, and the
preprocessor macro `SYCL_BACKEND_CUDA` will be defined.

The CUDA backend requires an installation of CUDA SDK as well as one or more
CUDA devices available in the system.

[[sec:cuda:mapping_of_sycl_programming_model]]
== Mapping of SYCL programming model

This section gives a general overview of how the SYCL programming model maps to
CUDA. These two programming models are pretty similar in essence however they do
have a few differences in terminology and architecture.

[[sub:cuda:platform_model]]
=== Platform Model

TODO: Platform

TODO: Device

A SYCL <<context>> simply maps to one, or multiple CUDA contexts. Indeed while
a CUDA context is tied to a single device, this is not the case for a SYCL
<<context>> and the CUDA backend implementation may use multiple CUDA contexts
to emulate a SYCL <<context>> containing multiple devices. Additionally, while
SYCL contexts are simple objects passed around either implicitly or explicitly,
CUDA contexts require to be activated on the current thread to be used by other
CUDA entry points. Therefore any use of the SYCL APIs with a CUDA backend may
modify the current active context on the thread, and no guarantee is provided
that any existing active CUDA context would be restored by SYCL.

A SYCL <<queue>> simply maps to one or multiple CUDA streams. Indeed while a
CUDA stream is in-order, a SYCL <<queue>> isn't, so a CUDA backend implementation
may use multiple CUDA streams to implement an out of order SYCL <<queue>>.

[[sub:cuda:memory_model]]
=== Memory model

[[sub:cuda:execution_model]]
=== Execution Model

[[sec::programming_interface]]
== Programming Interface

[[sub:cuda:application_interoperability]]
=== Application Interoperability

[[table.cuda.appinterop.nativeobjects]]
.Types of native backend objects application interoperability
[width="100%",options="header",cols="20%,20%,20%,40%"]
|====
| [code]#SyclType#                                                   | [code]#backend_input_t<backend::cuda, SyclType># | [code]#backend_return_t<backend::cuda, SyclType># | Description
| [code]#buffer# |   |   |
| [code]#context#                                                   |   |   |
| [code]#device#                                                    |   |   |
| [code]#device_image<State>#                                       |   |   |
| [code]#event#                                                     |   |   |
| [code]#kernel#                                                    |   |   |
| [code]#kernel_bundle<State>#                                      |   |   |
| [code]#platform#                                                  |   |   |
| [code]#queue#                                                     |   |   |
| [code]#sampled_image<Dims, AllocatorT>#                           |   |   |
| [code]#unsampled_image<Dims, AllocatorT>#                         |   |   |
|====

[[table.cuda.appinterop.ownership]]
.Ownership behavior of native backend objects.
[width="100%",options="header",cols="40%,60%"]
|====
| SYCL Object                                                       | Destructor behaviour
| [code]#buffer# |   
| [code]#context#                                                   |   
| [code]#device#                                                    |  
| [code]#device_image<State>#                                       |   
| [code]#event#                                                     |  
| [code]#kernel#                                                    |   
| [code]#kernel_bundle<State>#                                      |   
| [code]#platform#                                                  |  
| [code]#queue#                                                     |   
| [code]#sampled_image<Dims, AllocatorT>#                           |   
| [code]#unsampled_image<Dims, AllocatorT>#                         | 
|====

[[table.cuda.appinterop.make_interop_APIs]]
.[code]#make_*# Interoperability APIs for native backend objects.
[width="100%",options="header",cols="40%,60%"]
|====
| CUDA interoperability function                                    |  Description
| [code]#template<backend Backend> +
platform + 
make_platform(const backend_input_t<Backend, platform> &backendObject);# 
        |

| [code]#template<backend Backend> +
device +
make_device(const backend_input_t<Backend, device> &backendObject);# 
        |

| [code]#template<backend Backend> +
context +
make_context(const backend_input_t<Backend, context> &backendObject,
                     const async_handler asyncHandler = {});# 
        |

| [code]#template<backend Backend> +
queue +
make_queue(const backend_input_t<Backend, queue> &backendObject,
                 const context &targetContext,
                 const async_handler asyncHandler = {});# 
        |

| [code]#template<backend Backend> +
event +
make_event(const backend_input_t<Backend, event> &backendObject,
                 const context &targetContext);# 
        |

| [code]#template <backend Backend, typename T, int dimensions = 1,
          typename AllocatorT = buffer_allocator<std::remove_const_t<T>>> +
buffer<T, dimensions, AllocatorT> +
make_buffer(const backend_input_t<Backend, buffer<T, dimensions, AllocatorT>>
                &backendObject,
            const context &targetContext, event availableEvent);# 
        |

| [code]#template <backend Backend, typename T, int dimensions = 1,
          typename AllocatorT = buffer_allocator<std::remove_const_t<T>>> +
buffer<T, dimensions, AllocatorT> +
make_buffer(const backend_input_t<Backend, buffer<T, dimensions, AllocatorT>>
                &backendObject,
            const context &targetContext);# 
        |

| [code]#template <backend Backend, int dimensions = 1,
          typename AllocatorT = sycl::image_allocator> +
sampled_image<dimensions, AllocatorT> + 
make_sampled_image(
    const backend_input_t<Backend, sampled_image<dimensions, AllocatorT>>
        &backendObject,
    const context &targetContext, image_sampler imageSampler,
    event availableEvent);# 
        |

| [code]#template <backend Backend, int dimensions = 1,
          typename AllocatorT = sycl::image_allocator> +
sampled_image<dimensions, AllocatorT> +
make_sampled_image(
    const backend_input_t<Backend, sampled_image<dimensions, AllocatorT>>
        &backendObject,
    const context &targetContext, image_sampler imageSampler);# 
        |

| [code]#template <backend Backend, int dimensions = 1,
          typename AllocatorT = sycl::image_allocator> +
unsampled_image<dimensions, AllocatorT> +
make_unsampled_image(
    const backend_input_t<Backend, unsampled_image<dimensions, AllocatorT>>
        &backendObject,
    const context &targetContext, event availableEvent);# 
        |

| [code]#template <backend Backend, int dimensions = 1,
          typename AllocatorT = sycl::image_allocator> +
unsampled_image<dimensions, AllocatorT> + 
make_unsampled_image(
    const backend_input_t<Backend, unsampled_image<dimensions, AllocatorT>>
        &backendObject,
    const context &targetContext);# 
        |

| [code]#template<backend Backend, bundle_state State> +
kernel_bundle<State> +
make_kernel_bundle(
    const backend_input_t<Backend, kernel_bundle<State>> &backendObject,
    const context &targetContext);# 
        |

| [code]#template<backend Backend> +
kernel +
make_kernel(const backend_input_t<Backend, kernel> &backendObject,
                   const context &targetContext);# 
        |
|====

[[table.cuda.appinterop.make_interop_APIs]]
.[code]#get_native# Interoperability APIs for native backend objects.
[width="100%",options="header",cols="40%,60%"]
|====
| CUDA interoperability function                                    |  Description
| [code]#template<backend Backend, class T> +
backend_return_t<Backend, T> +
get_native(const T &syclObject);# 
        |
|====


[[sub:cuda:kernel_function_interoperability]]
=== Kernel Function Interoperability

[[table.cuda.appinterop.nativeobjects]]
.Types of native backend objects kernel function interoperability
[width="100%",options="header",cols="20%,20%,20%,40%"]
|====
| [code]#SyclType#                                                   | [code]#backend_input_t<backend::cuda, SyclType># | [code]#backend_return_t<backend::cuda, SyclType># | Description
| [code]#accessor<T, Dims, Mode, target::device>#                    |   |   |
| [code]#accessor<T, Dims, Mode, target::constant_buffer>#           |   |   |
| [code]#accessor<T, Dims, Mode, target::local>#                     |   |   |
| [code]#local_accessor<T, Dims>#                                    |   |   |
| [code]#sampled_image_accessor<T, 1, Mode, image_target::device>#   |   |   |
| [code]#sampled_image_accessor<T, 2, Mode, image_target::device>#   |   |   |
| [code]#sampled_image_accessor<T, 3, Mode, image_target::device>#   |   |   |
| [code]#unsampled_image_accessor<T, 1, Mode, image_target::device># |   |   |
| [code]#unsampled_image_accessor<T, 2, Mode, image_target::device># |   |   |
| [code]#unsampled_image_accessor<T, 3, Mode, image_target::device># |   |   |
| [code]#stream#                                                     |   |   |
| [code]#device_event#                                               |   |   |
|====


[[sec:non_core_features_and_extensions]]
== Non-core features and extensions

[[sub:cuda:extensions]]
=== Extensions

[[sub:cuda:error_handling]]
=== Error Handling

// %%%%%%%%%%%%%%%%%%%%%%%%%%%% end cuda_backend %%%%%%%%%%%%%%%%%%%%%%%%%%%%
