// %%%%%%%%%%%%%%%%%%%%%%%%%%%% begin cuda_backend %%%%%%%%%%%%%%%%%%%%%%%%%%%%

[appendix]
[[chapter:cuda-backend]]
= CUDA backend specification

This chapter describes how the SYCL general programming model is mapped on top
of CUDA, and how the SYCL generic interoperability interface must be
implemented by vendors providing SYCL for CUDA implementations to ensure SYCL
applications written for the CUDA backend are interoperable.

The CUDA backend is enabled using the `sycl::backend::cuda` value of `enum
class backend`. That means that when the CUDA backend is active, the value of
`sycl::is_backend_active<sycl::backend::cuda>::value` will be `true`, and the
preprocessor macro `SYCL_BACKEND_CUDA` will be defined.

The CUDA backend requires an installation of CUDA SDK as well as one or more
CUDA devices available in the system.
[[sec:cuda:introduction]]
== Introduction

[[sec:cuda:mapping_of_sycl_programming_model]]
== Mapping of SYCL programming model

This section gives a general overview of how the SYCL programming model maps to
CUDA. These two programming models are pretty similar in essence however they do
have a few differences in terminology and architecture.

[[sub:cuda:platform_model]]
=== Platform Model

All CUDA enabled devices which can be executed on are represented by a single `CUdevice`. A SYCL device maps to a single CUDA device.
As CUDA does not split into separate platforms there is no 'platform' concept in CUDA corresponding to the SYCL platform. Instead, a SYCL platform maps to a collection of CUDA devices represented by `std::vector<CUdevice>`.

A SYCL <<context>> simply maps to one, or multiple CUDA contexts. Indeed while
a CUDA context is tied to a single device, this is not the case for a SYCL
<<context>> and the CUDA backend implementation may use multiple CUDA contexts
to emulate a SYCL <<context>> containing multiple devices. Additionally, while
SYCL contexts are simple objects passed around either implicitly or explicitly,
CUDA contexts require to be activated on the current thread to be used by other
CUDA entry points. Therefore any use of the SYCL APIs with a CUDA backend may
modify the current active context on the thread, and no guarantee is provided
that any existing active CUDA context would be restored by SYCL.

A SYCL <<queue>> simply maps to one or multiple CUDA streams. Indeed while a
CUDA stream is in-order, a SYCL <<queue>> isn't, so a CUDA backend implementation
may use multiple CUDA streams to implement an out of order SYCL <<queue>>.

[[sub:cuda:memory_model]]
=== Memory model

==== Memory Allocations

When non-host accessors to buffers are created without [code]#target::host_buffer# they need to allocate memory for their contents on the device. For example using [code]#cudaMalloc3D()#, [code]#cudaMallocPitch()# or [code]#cudaMalloc()#.

When accessors to images are created without [code]#target::host_buffer# they allocate memory, for example using [code]#cudaMalloc3DArray()# or [code]#cudaMallocArray()#. 

When non-host accessors are created with [code]#target::host_buffer# they can, for example use [code]#cudaHostAlloc()# to allocate pinned memory on host.

Table <<table.cuda.memmodel.USM>> specifies which underlying CUDA functions can be used for USM allocations. For shared USM allocations this would mean memory is managed (moved between host and different devices) by CUDA runtime. Alternatively shared USM allocations can be managed by SYCL runtime, using non-managed CUDA allocation on device when needed, such as [code]#cudaMalloc()#.

[[table.cuda.memmodel.USM]]
.Cuda functions that could be used to allocate SYCL USM allocations
[width="100%",options="header",cols="50%,50%"]
|====
| SYCL USM type | CUDA function
| device | [code]#cudaMalloc()#
| host | [code]#cudaHostAlloc()#
| shared | [code]#cudaMallocManaged()#
|====

==== Samplers

In both SYCL and CUDA samplers consist of addressing mode, filtering mode and coordinate normalization mode. Mapping between SYCL and CUDA values is defined in tables <<table.cuda.memmodel.sampler_addressing>>, <<table.cuda.memmodel.sampler_filtering>> and <<table.cuda.memmodel.sampler_normalization>>. In CUDA addressing modes for all dimesnions will be the same, as CUDA allows different addressing modes for different dimesnions, while SYCL does not. 

[[table.cuda.memmodel.sampler_addressing]]
.Mapping of SYCL sampler addressing modes to CUDA
[width="100%",options="header",cols="50%,50%"]
|====
| SYCL sampler addressing mode | CUDA sampler addressing mode
| [code]#sycl::addressing_mode::mirrored_repeat# | [code]#cudaAddressModeMirror#
| [code]#sycl::addressing_mode::repeat# | [code]#cudaAddressModeWrap#
| [code]#sycl::addressing_mode::clamp_to_edge# | [code]#cudaAddressModeClamp#
| [code]#sycl::addressing_mode::clamp# | [code]#cudaAddressModeClamp#
| [code]#sycl::addressing_mode::none# | [code]#cudaAddressModeBorder#
|====

SYCL allows [code]#sycl::addressing_mode::mirrored_repeat# and [code]#sycl::addressing_mode::repeat# to be used together with unnormalized coordinates. In this case the resulting coordinates are undefined. CUDA does not allow this, so if [code]#sycl::addressing_mode::mirrored_repeat# or [code]#sycl::addressing_mode::repeat# is specified together with unnormalized coordinates, [code]#cudaAddressModeBorder# is used instead.

[[table.cuda.memmodel.sampler_filtering]]
.Mapping of SYCL sampler filtering modes to CUDA
[width="100%",options="header",cols="50%,50%"]
|====
| SYCL sampler filtering mode | CUDA sampler filtering mode
| [code]#sycl::filtering_mode::nearest# | [code]#cudaFilterModePoint#
| [code]#sycl::filtering_mode::linear# | [code]#cudaFilterModeLinear#
|====

[[table.cuda.memmodel.sampler_normalization]]
.Mapping of SYCL sampler coordinate normalization modes to CUDA
[width="100%",options="header",cols="50%,50%"]
|====
| SYCL sampler coordinate normalization mode | CUDA sampler coordinate normalization mode
| [code]#sycl::coordinate_normalization_mode::normalized# | [code]#normalizedCoords = true#
| [code]#sycl::coordinate_normalization_mode::unnormalized# | [code]#normalizedCoords = false#
|====

==== Address Spaces

Table <<table.cuda.memmodel.address_spaces>> maps SYCL address spaces to CUDA address spaces.

[[table.cuda.memmodel.address_spaces]]
.Mapping from SYCL address spaces to CUDA address spaces
[width="100%",options="header",cols="50%,50%"]
|====
| SYCL Address Space | CUDA Address Space
| Global memory | global
| Local memory | shared
| Private memory | registers or local
| Generic memory | generic
| Constant memory | const
|====

==== Atomics

Not all CUDA devices support all memory orders. If a particular memory order is unsupported by a CUDA device, it can be unsupported in the SYCL CUDA backend for that device. Sequentially consistent atomics are currently not supported on any device, so the SYCL CUDA backend is not required to implement them. The mappings of other memory orders (when supported by the device) is defined in table <<table.cuda.memmodel.memory_orders>>.

[[table.cuda.memmodel.memory_orders]]
.Mapping from [code]#sycl::memory_order# to PTX ISA memory orders
[width="100%",options="header",cols="50%,50%"]
|====
| [code]#sycl::memory_order# | PTX ISA Memory Order
| [code]#memory_order::relaxed# | relaxed
| [code]#memory_order::acquire# | acquire
| [code]#memory_order::release# | release
| [code]#memory_order::acq_rel# | acq_rel
| [code]#memory_order::seq_cst# | undefined
|====

Mapping of memory scopes (when supported by the device) is defined in table [table.cuda.memmodel.memory_scopes]. [code]#memory_scope::work_item# does not require any consistency between different work items, so it can be mapped to non-atomic operation.

[[table.cuda.memmodel.memory_scopes]]
.Mapping from [code]#sycl::memory_scope# to PTX ISA memory scopes
[width="100%",options="header",cols="50%,50%"]
|====
| [code]#sycl::memory_scope# | PTX ISA Memory Scope
| [code]#memory_scope::work_item# | 
| [code]#memory_scope::sub_group# | cta
| [code]#memory_scope::work_group# | cta
| [code]#memory_scope::device# | gpu
| [code]#memory_scope::system# | system
|====

==== Fences

If a device supports the [code]#fence# PTX instruction the mapping of memory orders is defined in <<table.cuda.memmodel.fence_memory_orders>>. Otherwise all memory orders (except relaxed) are mapped to the [code]#membar# instruction.

[[table.cuda.memmodel.fence_memory_orders]]
.Mapping from [code]#sycl::memory_order# to PTX ISA memory orders when used in fences
[width="100%",options="header",cols="50%,50%"]
|====
| [code]#sycl::memory_order# | PTX ISA Memory Order
| [code]#memory_order::relaxed# | none
| [code]#memory_order::acquire# | acq_rel
| [code]#memory_order::release# | acq_rel
| [code]#memory_order::acq_rel# | acq_rel
| [code]#memory_order::seq_cst# | sc
|====

If future versions of PTX ISA define fence instructions with only acquire or only release memory order, these can be used as well for [code]#memory_order::acquire# and [code]#memory_order::release# on devices that support them.

Mapping of SYCL memory scopes to PTX ISA is the same as for atomics. It is defined in <<table.cuda.memmodel.memory_scopes>>.

[[sub:cuda:execution_model]]
=== Execution Model

CUDA's execution model is similar to SYCL's. CUDA uses kernels to
offload computation, splitting the host and GPU into asynchronous 
computing devices. In general, except for CUDA's dynamic 
parallelism extensions, kernels are called by the host. One 
difference between CUDA and SYCL execution models is that CUDA 
uses Single Instruction Multiple Thread (SIMT) while SYCL uses 
Single Instruction Multiple Data (SIMD) kernels. SIMT kernels use 
multiple scalar instructions acting on non-contiguous data.  SIMD 
kernels use vector instructions acting on contiguous data. SIMT 
can be used in place of SIMD but not the other way around, as SIMD 
requires memory blocks to have no interruptions within the data, 
while SIMT does not have this as a requirement. 

CUDA GPUs are constructed out of streaming multiprocessors (SM) 
which perform the actual computation. Each SM consists of 8 scalar 
cores, shared memory, registers, a load/store unit, and a scheduler 
unit. CUDA uses a hierarchy of threads to organize the execution of
kernels. Kernels are split up into thread blocks. The threadblocks 
form a grid each thread can identify its location within the grid 
using a block ID. The grid is a concept used to index threadblocks 
the grid can be one, two, or three dimensions. Each thread block is 
tied to a single SM. Similar to a thread block's location within the 
grid, each thread's position within the block can be identified with 
a one, two, or three dimensional thread ID. 

Pre-Volta GPU architectures breaks thread blocks into warps which 
consist of 32 threads. The warp is processed by the SM concurrently. 
For one warp instruction to be executed requires 4 SM clock cycles. 
SM's execute multiple warp instructions. The warps instructions are 
prioritized and scheduled to minimize overhead. 

Volta and more recent GPU architectures use independent thread 
scheduling. In addition, each thread can access memory within a 
unified virtual address space. Threads must synchronize with other 
threads using execution barriers, synchronization primitives and 
Cooperative Groups to utilize unified memory.

SYCL has a similar execution hierarchy consisting of kernels. 
The kernel is broken down into work-items. Each work-item concurrently
executes an instance of the kernel on a piece of memory. Work-items 
can be combined into work-groups that have designated shared memory.
Work-groups can synchronize their work-items with work-group barriers.

There are some equivalences between CUDA and SYCL execution models. 
For example, CUDA's stream multiprocessor is equal to a SYCL compute 
unit. CUDA's grid is similar to SYCL's nd_range as it is the highest 
level grouping of threads, not including the whole kernel. Both 
nd_range and grid can segment the groups of threads into one, two, or 
three dimensions. SYCL sub-groups roughly map to
cooperative groups `thread_block_tile` as it allows for the
work-group/thread block to be further subdivided into concurrent threads.
Likewise, thread blocks map directly to work-groups, and a
single thread is a SYCL work-item.

CUDA primarily synchronizes the threads through two functions,
`cudaStreamSynchronize()` and `__syncthreads()`. 
`cudaStreamSynchronize()` blocks work from being performed until all 
threads on the device has been completed. `__syncthreads()` waits for 
all threads within a thread block to reach the same point. So 
`cudaStreamSynchronize()` is similar to queue.wait(), buffer 
destruction, and other host-device synchronization events within SYCL. 
`__syncthreads()` synchronizes the threads within a thread block which
is analogous to the work-group barrier.

CUDA's warp concept has no SYCL equivalent. If a user were to write 
warp aware code it would be non-generic SYCL code and specific to the 
CUDA backend.

CUDA allows for more detailed thread and memory management through 
Cooperative Groups. Cooperative Groups allow for synchronizing at the 
grid level and organizing subgroups in sizes smaller than a warp. 
Cooperative Groups do not have an equivalent within SYCL 2020 and are 
not yet supported.

[[table.cuda.CUDA_features_to_SYCL]]
.CUDA execution features with their corresponding SYCL features
[width="100%",options="header",cols="50%,50%"]
|====
| [code]#SYCL#                                                       | [code]#CUDA#
| [code]#Compute unit#                                               | [code]#Streaming multiprocessor#
| [code]#nd_range#                                                   | [code]#grid#
| [code]#work-group#                                                 | [code]#Thread block#
| [code]#sub-group#                                                  | [code]#thread_block_tile#
| [code]#work-item#                                                  | [code]#Thread#
| [code]#SYCL nd_item synchronization#                               | [code]#cudaStreamSynchronize#
| [code]#work-group barrier#                                         | [code]#__syncthread#
|====

[[sec::programming_interface]]
== Programming Interface

[[sub:cuda:application_interoperability]]
=== Application Interoperability

This section describes the API level interoperability between SYCL and CUDA.

The CUDA backend supports API interoperability for `platform`, `device`,
`context`, `queue`, `event` and `buffer`. Interoperability for `kernel`,
`kernel_bundle`, `device_image`, `sampled_image` and `unsampled_image` is not
supported.

[[table.cuda.appinterop.nativeobjects]]
.Types of native backend objects application interoperability
[width="100%",options="header",cols="20%,20%,20%,40%"]
|====
| [code]#SyclType# | [code]#backend_input_t<backend::cuda, SyclType># | [code]#backend_return_t<backend::cuda, SyclType># | Description
| [code]#platform# | `std::vector<CUdevice>`   | `std::vector<CUdevice>`  | A SYCL platform encapsulates a list of CUDA devices.
| [code]#device#   | `CUdevice`                | `CUdevice`               | A SYCL device encapsulates a CUDA device.
| [code]#context#  | `CUcontext`               | `std::vector<CUcontext>` | A SYCL context can encapsulate multiple CUDA contexts , however it is not possible to create a SYCL context from multiple CUDA contexts.
| [code]#queue#    | `CUstream`   | `CUstream` | A SYCL queue encapsulates a CUDA stream.
| [code]#event#    | `CUevent`    | `CUevent`  | A SYCL event encapsulates a CUDA event.
| [code]#buffer# | `struct { CUdeviceptr ptr; size_t size; }` | `CUdeviceptr` | A SYCL buffer encapsulates a CUDA device pointer.
|====

[[table.cuda.appinterop.make_interop_APIs]]
.[code]#make_*# Interoperability APIs for native backend objects.
[width="100%",options="header",cols="40%,60%"]
|====
| CUDA interoperability function                                    |  Description
| [code]#template<backend Backend> +
platform + 
make_platform(const backend_input_t<Backend, platform> &backendObject);# 
        | Create a SYCL `platform` from a list of CUDA device, the list must contain at least one CUDA device.

| [code]#template<backend Backend> +
device +
make_device(const backend_input_t<Backend, device> &backendObject);# 
        | Create a SYCL `device` from a CUDA device.

| [code]#template<backend Backend> +
context +
make_context(const backend_input_t<Backend, context> &backendObject,
                     const async_handler asyncHandler = {});# 
        | Create a SYCL `context` from a CUDA context.

| [code]#template<backend Backend> +
queue +
make_queue(const backend_input_t<Backend, queue> &backendObject,
                 const context &targetContext,
                 const async_handler asyncHandler = {});# 
        | Create a SYCL `queue` from a CUDA stream. The provided `targetContext` must encapsulate the same CUDA context as the provided CUDA stream.

| [code]#template<backend Backend> +
event +
make_event(const backend_input_t<Backend, event> &backendObject,
                 const context &targetContext);# 
        | Create a SYCL `event` from a CUDA event.

| [code]#template <backend Backend, typename T, int dimensions = 1,
          typename AllocatorT = buffer_allocator<std::remove_const_t<T>>> +
buffer<T, dimensions, AllocatorT> +
make_buffer(const backend_input_t<Backend, buffer<T, dimensions, AllocatorT>>
               &backendObject,
           const context &targetContext, event availableEvent);#
        | Create a SYCL `buffer` from a CUDA device pointer.` The CUDA pointer must be within the provided `targetContext`. The `availableEvent` parameter can be used for synchronization and indicates when the CUDA pointer is ready to be used. Only `dimensions == 1` is supported.
 
| [code]#template <backend Backend, typename T, int dimensions = 1,
           typename AllocatorT = buffer_allocator<std::remove_const_t<T>>> +
buffer<T, dimensions, AllocatorT> +
make_buffer(const backend_input_t<Backend, buffer<T, dimensions, AllocatorT>>
                &backendObject,
            const context &targetContext);#
        | Create a SYCL `buffer` from a CUDA device pointer.` The CUDA pointer must be within the provided `targetContext`. Only `dimensions == 1` is supported.

|====

==== Ownership of native backend objects

The CUDA backend retains ownership of all native CUDA objects obtained through
the interoperability API, therefore associated SYCL objects must be kept alive
for the duration of the CUDA work using these native CUDA objects.
dd CUDA backend specification kernel function interop definitions

When creating a SYCL object from a native CUDA object SYCL does not take
ownership of the object and it is up to the application to dispose of them when
appropriate.

[[sub:cuda:kernel_function_interoperability]]
=== Kernel Function Interoperability

This section describes the kernel function interoperability for the CUDA
backend.

The CUDA backend supports kernel function interoperability for the `accessor`,
`local_accessor`, `sampled_image_accessor`, `unsampled_image_accessor` and
`stream` classes.

The CUDA backend does not support interoperability for the `device_event` class
as there's no equivalent in CUDA.

Address spaces in CUDA are associated with variable decorations rather than the
type, so when pointers are passed as parameters to a function the parameter
types does not need to be decorated with an address space, instead it's simply a
raw un-decorated pointer. For this reason the `accessor`,  `local_accessor` and
`stream` classes map to a raw undecorated pointer which can be implemented using
the generic address space.

Other kernel function types in CUDA are represented by aliases provided in the
`sycl::cuda` namespace. These are provided for the `sampled_image_accessor`,
and `unsampled_image_accessor` classes; `sycl::cuda::texture` and
`sycl::cuda::surface` respectively.

Below is a table of the `backend_input_t` and `backend_return_t` specializations
for the SYCL classes which support kernel function interoperability.

[[table.cuda.kernelinterop.nativeobjects]]
.Types of native backend objects kernel function interoperability
[width="100%",options="header",cols="20%,20%,20%,40%"]
|====
| [code]#SyclType#                                                   | [code]#backend_input_t<backend::cuda, SyclType># | [code]#backend_return_t<backend::cuda, SyclType># | Description
| [code]#accessor<T, Dims, Mode, target::device>#                    | T * | T * | Convert a SYCL `accessor` to an undecorated raw pointer.
| [code]#accessor<T, Dims, Mode, target::constant_buffer>#           | T * | T * | Convert a SYCL `accessor` to an undecorated raw pointer.
| [code]#accessor<T, Dims, Mode, target::local>#                     | T * | T * | Convert a SYCL `accessor` to an undecorated raw pointer.
| [code]#local_accessor<T, Dims>#                                    | T * | T * | Convert a SYCL `accessor` to an undecorated raw pointer.
| [code]#sampled_image_accessor<T, 1, Mode, image_target::device>#   | sycl::cuda::texture<T, 1> | sycl::cuda::texture<T, 1> | Convert a SYCL `accessor` to the `sycl::cuda::texture` interoperability type with the same type and dimensions.
| [code]#sampled_image_accessor<T, 2, Mode, image_target::device>#   | sycl::cuda::texture<T, 2> | sycl::cuda::texture<T, 1> | Convert a SYCL `accessor` to the `sycl::cuda::texture` interoperability type with the same type and dimensions.
| [code]#sampled_image_accessor<T, 3, Mode, image_target::device>#   | sycl::cuda::texture<T, 3> | sycl::cuda::texture<T, 1> | Convert a SYCL `accessor` to the `sycl::cuda::texture` interoperability type with the same type and dimensions.
| [code]#unsampled_image_accessor<T, 1, Mode, image_target::device># | sycl::cuda::surface<T, 1> | sycl::cuda::surface<T, 1> | Convert a SYCL `accessor` to the `sycl::cuda::surface` interoperability type with the same type and dimensions.
| [code]#unsampled_image_accessor<T, 2, Mode, image_target::device># | sycl::cuda::surface<T, 2> | sycl::cuda::surface<T, 1> | Convert a SYCL `accessor` to the `sycl::cuda::surface` interoperability type with the same type and dimensions.
| [code]#unsampled_image_accessor<T, 3, Mode, image_target::device># | sycl::cuda::surface<T, 3> | sycl::cuda::surface<T, 1> | Convert a SYCL `accessor` to the `sycl::cuda::surface` interoperability type with the same type and dimensions.
| [code]#stream#                                                     | signed char * | signed char * | Convert a SYCL `accessor` to an undecorated raw signed char pointer.
|====


[[sec:non_core_features_and_extensions]]
== Non-core features and extensions

Additional CUDA features are available depending upon the devices compute capability.
SYCL can support these optional CUDA features with extensions.
Unlike OpenCL, CUDA needs to know if the extension is available at compile time. 
As a result there are no valid CUDA extensions which can be passed to `has_extension`.

As the extension must be known at runtime CUDA extensions are best implemented 
using feature test macros. The test macro format is 
SYCL_EXT_<vendorstring>_<featurename>. For CUDA extensions this format translates 
to SYCL_EXT_NVIDIA_<featurename>. Similarly, the format for the naming of extension 
classes and enumerations should be ext_<vendorstring>_<featurename>. Which in this context
becomes ext_NVIDIA_<featurename>. Given the necessity to know the extension at 
compile-time, the usage of extension macros should be the primary method of determining 
if the extension is available in the SYCL implementation not. 
A list of non-core CUDA features which have SYCL support is below.
Non-core CUDA features for require a compute capability of greater than 5.

TODO: The table below shows a proposal for SYCL supported CUDA extensions.
The table should be developed with other members of the SYCL community.

[[table.extensionsupport]]
.SYCL support for CUDA 11.3 extensions
[width="100%",options="header",cols="35%,35%,15%, 15"]
|====
| SYCL Aspect              | CUDA Extension                                        | Core SYCL API | Required Compute Capability 
| [code]#aspect::fp16#     | [code]#16-bit floating point#                         | Yes           | 5.3 or greater
| -                        | [code]#Tensor Cores#                                  | No            | 7 or greater
| -                        | [code]#Atomic floating-point operations#              | No            | 6 or greater
|====

=== Aspects
Aspects are used to query what features and attributes a device has. Some aspects such as `fp16`
are non-core CUDA features. Therefore, the runtime must be able to determine what aspects CUDA 
devices have. This can be performed by querying `cudaDeviceProp::major` and `cudaDeviceProp::minor`
to find out the compute capability. The compute capability indicates what extensions are
available to the device, and therefore what aspects are available.

[[sec:cuda:extension-fp16]]
=== Half precision floating-point

The half scalar data type: [code]#half# and the half vector data types:
[code]#half1#, [code]#half2#, [code]#half3#,
[code]#half4#, [code]#half8# and [code]#half16# must be
available at compile-time. However a kernel using these types is only
supported on devices that have [code]#aspect::fp16#, i.e. compute capability
5.3 or greater.

[[sub:cuda:extensions]]
=== Extensions

[[sub:cuda:error_handling]]
=== Error Handling

If there is a CUDA driver API error associated with an exception triggered, then the
CUDA error code can be obtained by the free function `CUresult sycl::cuda::get_error_code(sycl::exception&)`. In the case where there is
no CUDA error associated with the exception triggered, the CUDA error
code will be `CUDA_SUCCESS`.

Most of the SYCL error codes that form sycl::errc are specifically defined as errors thrown during calls to the SYCL API or SYCL runtime. There are also some cases of sycl::errc which cover errors thrown during the compilation or execution of device code.
It is suitable to map CUDA errors to such cases, such that an exception, "cuda_exception", that was created due to a CUDA error, may, upon execution of `cuda_exception.code()`, return a `std::error_code` relating to the `sycl::errc` case that the CUDA error maps to; whilst `sycl::cuda::get_error_code(cuda_exception)` will return the original CUDA error code.

The relevant `sycl::errc` cases and the CUDA errors that they may be mapped from are listed below.

==== build

`sycl::errc::build` is defined as:

_Error from an online compile or
link operation when compiling,
linking, or building a kernel bundle for a device._

which may be mapped from `CUDA_ERROR_NO_BINARY_FOR_GPU`, `CUDA_ERROR_JIT_COMPILER_NOT_FOUND`, `CUDA_ERROR_INVALID_PTX`, `CUDA_ERROR_UNSUPPORTED_PTX_VERSION`, `CUDA_ERROR_SHARED_OBJECT_INIT_FAILED`, `CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND`.


==== memory_allocation

`sycl::errc::memory_allocation` is defined as:

_Error on memory allocation on the
SYCL device for a SYCL kernel._

which may be mapped from `CUDA_ERROR_OUT_OF_MEMORY`.

==== kernel_argument

`sycl::errc::kernel_argument` is defined as:

_The application has passed an invalid argument to a SYCL kernel
function. This includes captured
variables if the SYCL kernel function is a lambda function._

which may be mapped from `CUDA_ERROR_NOT_FOUND`.

// %%%%%%%%%%%%%%%%%%%%%%%%%%%% end cuda_backend %%%%%%%%%%%%%%%%%%%%%%%%%%%%
